{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "I'm working with non spatially-referenced images produced from a laser ablation system. Along with the image, the software produces an \"align\" file of the same name - an xml file that contains the XY center point of each image (coordinates are in microns) and the XY size (in microns) along with any rotation. \n",
    "\n",
    "I would like to display the images (we typically generate about 1000 images / day) in their correct relative positions and sizes.\n",
    "\n",
    "The laser has a stage with a cartesian positive XY coordinate system (in microns), and the origin in the SW corner. \n",
    "\n",
    "Is there a way to either turn the images into georeferenced geotiffs (using the information in the xml file)? So far I have gotten to the step of generating an affine transform for each scanned image based on it's size and center coordinate in microns and rotation metadata. What I don't have is a definition of a custom CRS in WKT. I don't have any experience with the WKt format but it seems like the only way to represent non-Earth CRSs.\n",
    "\n",
    "Are there any resources for defining a custom CRS in WKT? I know the units are in microns, the center point of my datum, and the height and width of the coordinate reference system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching png paths to metadata paths and extracting the metadata into tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import skimage.io as skio\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as et \n",
    "import numpy as np\n",
    "import affine\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "def match_png_align(png_file_path, align_file_path):\n",
    "    \"\"\"Tests if png and align file IDs are the same.\"\"\"\n",
    "    png_lst = str(png_file_path.name).split(\"_\")\n",
    "    align_lst = str(align_file_path.name).split(\"_\")\n",
    "    if png_lst[1] == align_lst[1] \\\n",
    "    and png_lst[2] == align_lst[2] \\\n",
    "    and png_lst[3] == align_lst[3] \\\n",
    "    and png_lst[-1][:-4] == align_lst[-1][:-6]:\n",
    "        return (png_file_path, align_file_path)\n",
    "\n",
    "\n",
    "def read_transform_inputs_png(meta_path):\n",
    "    \"\"\"Reads xml info about the scanned image used to transform coordinates\"\"\"\n",
    "    xtree = et.parse(meta_path)\n",
    "    root = xtree.getroot()\n",
    "    center_info = root[0][2].text.split(\",\")\n",
    "    size_info = root[0][3].text.split(\",\")\n",
    "    extra_info = root[0][0].text.split(\";\")\n",
    "    return {\"rotation\": float(root[0][1].text), \n",
    "           \"center_x\": float(center_info[0]),\n",
    "           \"center_y\" : float(center_info[1]),\n",
    "           \"size_x\" : float(size_info[0]),\n",
    "           \"size_y\" : float(size_info[1]),\n",
    "           \"brightness\": float(extra_info[0].split(\"=\")[1]),\n",
    "           \"contrast\": float(extra_info[1].split(\"=\")[1]),\n",
    "           \"autoexposure\": float(extra_info[2].split(\"=\")[1]),\n",
    "           \"exposuretime\": float(extra_info[3].split(\"=\")[1])}\n",
    "\n",
    "def read_transform_inputs_datum(datum_path):\n",
    "    parser = et.XMLParser(encoding=\"utf-8\")\n",
    "    xtree = et.parse(datum_path, parser=parser)\n",
    "    root = xtree.getroot()\n",
    "    return {\n",
    "        \"rotation\" : float(root[0][0].text),\n",
    "        \"center_x\" : float(root[0][1].text.split(\",\")[0]),\n",
    "        \"center_y\" : float(root[0][1].text.split(\",\")[1]),\n",
    "        \"size_x\" : float(root[0][2].text.split(\",\")[0]),\n",
    "        \"size_y\" : float(root[0][2].text.split(\",\")[1]),\n",
    "        \"focus\" : float(root[0][3].text)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_p = Path(\"images/\")\n",
    "\n",
    "align_paths = list(images_p.glob(\"ScanImage*.Align\"))\n",
    "png_paths = list(images_p.glob(\"ScanImage*.png\"))\n",
    "\n",
    "matches = []\n",
    "for a in align_paths:\n",
    "    for p in png_paths:\n",
    "        if match_png_align(p, a):\n",
    "            matches.append((p,a))\n",
    "\n",
    "image_df = pd.DataFrame(matches, columns=[\"png\",\"meta\"])\n",
    "\n",
    "\n",
    "image_df = image_df.join(pd.json_normalize(image_df.meta.apply(read_transform_inputs_png)))\n",
    "\n",
    "image_df['source_shape'] = image_df.png.apply(lambda x: skio.imread(x).shape)\n",
    "\n",
    "image_df = image_df.join(pd.DataFrame(image_df['source_shape'].tolist(), index=image_df.index, columns=[\"source_size_y\", \"source_size_x\", \"source_size_band\"])  )  \n",
    "\n",
    "datum_im_p = list(images_p.glob(\"Image_1*\"))[0]\n",
    "datum_align_p = list(images_p.glob(\"Image_1*\"))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the transform for each png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format for the transfrm is (uperleftx, scalex, skewx, uperlefty, skewy, scaley) and defines how to map pixel coordinates to CRS coordinates. The only thing missing is a custom CRS that is defined from the datum image metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and Y pixel resolution of the datum image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['resolution_x'] = image_df['size_x'] / image_df['source_size_x']\n",
    "image_df['resolution_y'] = image_df['size_y'] / image_df['source_size_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the center and size in projection coordinate of each png scan, we can get the upper left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['upleftx'] = image_df.center_x - image_df.size_x / 2\n",
    "image_df['uplefty'] = image_df.center_y - image_df.size_y / 2\n",
    "# Specify raster location through geotransform array\n",
    "# (uperleftx, scalex, skewx, uperlefty, skewy, scaley)\n",
    "image_df[\"affine_transform\"] = image_df.apply(lambda row: affine.Affine(row['upleftx'], row['resolution_x'], row['rotation'], row['uplefty'], row['rotation'], -row['resolution_y']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to John, for the datum, we need to find the x and y size AFTER rotation by half a degree, the sizes in the metadata are pre rotation.\n",
    "\n",
    "The datum info here might not be necessary, except to reference the datum image since it is rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason this starts throwing a parse error. pulled the big image size and center out manually, put in georef func\n",
    "# datum_meta = read_transform_inputs_datum(str(datum_align_p))\n",
    "# datum_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Georeferences each png on a cartesian projection (epsg:6507) based on the upper left coordinate in microns, then saves as a geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georef(row, outfolder=\"output\"):\n",
    "    # might need these to define total bounds of the CRS but maybe not\n",
    "    center_x = 42085.00\n",
    "    center_y = 47699.00\n",
    "    size_x = 117207.00\n",
    "    size_y = 104307.00\n",
    "    src_filename = str(row[\"png\"])\n",
    "    \n",
    "    if os.path.exists(outfolder) == False:\n",
    "        os.mkdir(outfolder)\n",
    "    \n",
    "    dst_filename = os.path.join(outfolder, os.path.basename(str(row['png'])).split(\".\")[0] + \".tif\")\n",
    "    \n",
    "    # Opens source dataset\n",
    "    src_ds = gdal.Open(src_filename)\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    ds = driver.Create(dst_filename, xsize=int(row['source_size_x']), ysize=int(row['source_size_y']), bands=3)\n",
    "\n",
    "    # this assumes the projection is Geographic lat/lon WGS 84\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(6507)\n",
    "    ds.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "    gt = list(row['affine_transform'])[0:6]\n",
    "    ds.SetGeoTransform(gt)\n",
    "\n",
    "    outband = ds.GetRasterBand(1)\n",
    "    arr = skio.imread(src_filename)\n",
    "    arr = np.moveaxis(arr, -1, 0)\n",
    "    for i, band in enumerate(arr, 1):\n",
    "        ds.GetRasterBand(i).WriteArray(band)\n",
    "        \n",
    "# georef(image_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.apply(georef, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
